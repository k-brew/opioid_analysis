---
title: "Exploratory Data Analysis - Trends in Opioid Prescriptions"
author: "Kyle Brewster"
output: html_document
---

```{r setup, include=FALSE}
# synced with Github
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache=TRUE) ## Cache the results to increase performance.
```

# Data Cleaning & Setup
```{r load.csv & packages}
library(pacman)
p_load(dplyr, readr, skimr, ggplot2, tidyverse, tidymodels, janitor, magrittr)

opioid_list = read.csv("opioids.csv")
overdose_df = read.csv("overdoses.csv")
prescriber_df = read.csv("prescriber_info.csv")
```

## Overview
```{r skimm the data}
#skim(prescriber_df)
```

## Cleaning up
### The `Credentials` column
```{r cleaning various diff. names for cred., message=FALSE, warning=FALSE}
# To get an idea of some of the more-common types of credentials
top_counts(prescriber_df$Credentials, max_levels = 20)

# Cleaning up the acronyms for some of the most common types of credential
scribe_MD <- prescriber_df %>% 
  group_by(Credentials) %>%
  filter(Credentials == "MD"|
         Credentials == "M.D."|
         Credentials == "M.D"|
         Credentials == "M.D.,"|
         Credentials == "M,D"|
         Credentials == "MD."|
         Credentials == "M.D,"|
         Credentials == "M.D")
scribe_DDS <- prescriber_df %>% 
  filter(Credentials == "DDS"|
         Credentials == "DDS, MS,"|
         Credentials == "D.D.S."|
         Credentials == "DDS, MS"|
         Credentials == "DDS. MS"|
         Credentials == "MD, DDS"|
         Credentials == "DDS,MD"|
         Credentials == "DMD"| 
         Credentials == "D.M.D."|
         Credentials == "D.M.D"|
         Credentials == "DDS, MD")
scribe_DO <- prescriber_df %>% 
  group_by(Credentials) %>%
  filter(Credentials == "DO"|
         Credentials == "D.O."|
         Credentials == "D.O"|
         Credentials == "DO,"|
         Credentials == "D.O., M.D"|
         Credentials == "D.O., M.D."|
         Credentials == "D,O."|
         Credentials == "D.O.,")
scribe_PA <- prescriber_df %>% 
  group_by(Credentials) %>%
  filter(Credentials == "PA"|
         Credentials == "P.A."|
         Credentials == "P.A.-C"|
         Credentials == "PA-C"|
         Credentials == "P.A"|
         Credentials == "PA-"|
         Credentials == "PA,"|
         Credentials == "PA."|
         Credentials == "P,A."|
         Credentials == "P.A.C"|
         Credentials == "P.A.,")  
scribe_NP <- prescriber_df %>% 
  group_by(Credentials) %>%
  filter(Credentials == "NP"|
         Credentials == "N.P."|
         Credentials == "N.P"|
         Credentials == "NP."|
         Credentials == "NP,"|
         Credentials == "N.P.,"|
         Credentials == "N P"|
         Credentials == "NURSE PRACTITIONER"|
         Credentials == "NP-C"|
         Credentials == "NP."|
         Credentials == "N P")
    ## Now to make the values more uniform
scribe_DDS = replace(scribe_DDS, 4,"DDS_DDM")
scribe_DO  = replace(scribe_DO, 4, "DO")
scribe_MD  = replace(scribe_MD, 4, "MD")
scribe_PA  = replace(scribe_PA, 4, "PA")
scribe_NP  = replace(scribe_NP, 4, "NP")
```

```{r merging dataframes}
scribe_joint = rbind(scribe_DDS, scribe_DO,
                     scribe_MD, scribe_NP,
                     scribe_PA)
```

### The `Specialty` column
Looking at the top specialties
```{r top counts}
tab <- as.data.frame(table(prescriber_df$Specialty))
tab =arrange(tab, desc(Freq)) 
```
Filtering the data to only some the more-common values
```{r top counts filtering}
scribe_joint = scribe_joint %>%
  group_by(Specialty) %>%
  filter(Specialty == "Internal Medicine"|
         Specialty == "Family Practice"|
         Specialty == "Dentist"|
         Specialty == "Physician Assistant"|
         Specialty == "Nurse Practitioner"|
         Specialty == "Emergency Medicine"|
         Specialty == "Psychiatry"|
         Specialty == "Cardiology"|
         Specialty == "Obstetrics/Gynecology"|
         Specialty == "Orthopedic Surgery"|
         Specialty == "Optometry"|
         Specialty == "General Surgery")
```

### The State Naming Convention
Using the `state.abb` package to save some effort in narrowing this set down to 50 states and excluding territories, miscellaneous, or missing categories
```{r}
list_of_states = as.data.frame(cbind(state.abb))
list_of_states = list_of_states %>%
  mutate(State = state.abb) # Let's make the state variable have the same naming convention in both; and then filter out providers outside of our scope of interest
scribe_joint_nonstates = anti_join(scribe_joint, list_of_states, by = 'State')

# And now to get our sets for only the 50 states
scribe_joint = scribe_joint[
  !scribe_joint$State %in% scribe_joint_nonstates$State,
  ]
```

### Creating Variable for Total Number of Opioids Prescribed
Since we are working with multiple variables involving opioids, we therefore must avoid the mistake of including an opioid-variable in both the predictor and the outcome variables. Doing so would result in skewness of model accuracy since the predictors and the outcome are directly correlated and would predict an outcome that we already know.

Looking at the `opioid_list` data frame. 
```{r op. list}
unique(opioid_list$Generic.Name) # To see which medications are opioids
top_opioids = rbind(
  opioid_list[grep("BUPRENORPHINE", opioid_list$Generic.Name),],
  opioid_list[grep("BUTORPHANOL", opioid_list$Generic.Name),],
  opioid_list[grep("CODEINE", opioid_list$Generic.Name),],
  opioid_list[grep("FENTANYL", opioid_list$Generic.Name),],
  opioid_list[grep("HYDROCODONE", opioid_list$Generic.Name),],
  opioid_list[grep("HYDROMORPHONE", opioid_list$Generic.Name),],
  opioid_list[grep("LEVORPHANOL", opioid_list$Generic.Name),],  
  opioid_list[grep("MEPERIDINE", opioid_list$Generic.Name),],
  opioid_list[grep("METHADONE", opioid_list$Generic.Name),],
  opioid_list[grep("MORPHINE", opioid_list$Generic.Name),],
  opioid_list[grep("NALBUPHINE", opioid_list$Generic.Name),],
  opioid_list[grep("OPIUM", opioid_list$Generic.Name),],
  opioid_list[grep("OXYCODONE", opioid_list$Generic.Name),],
  opioid_list[grep("OXYMORPHONE", opioid_list$Generic.Name),],
  opioid_list[grep("PENTAZOCINE", opioid_list$Generic.Name),],
  opioid_list[grep("TRAMADOL", opioid_list$Generic.Name),])
```
Here we can see the drug class variables that are opioids from the original `prescriber_df`. Next we can use these different drug types to count the total number of prescriptions written by each provider.
```{r creating summ_var}
working_df = scribe_joint %>%
  select(contains(c("NPI","Gender","State","Credentials","Specialty",
                  "HYDROCODONE","OXYCONTIN",
                  "CODEINE","FENTANYL","PENTAZOCINE",
                  "DIHYDROCODEINE","Opioid.Prescriber",
                  "OPIUM","BUPRENORPHINE","BUTALBIT","BUTORPHANOL",
                  "TRAMADOL","MEPERIDINE","HYDROMORPHONE","METHADONE",
                  "MORPHINE","OXYCODONE","LEVORPHANOL","NALBUPHINE",
                  "TAPENTADOL","OXYMORPHONE","OPIUM")))

# Now we can calculate the sum of opioid prescription written by each provider for the year
working_df$summ_var = rowSums(working_df[ ,c(6:18)])

# adding that column to our original data frame
scribe_joint$summ_var <- working_df$summ_var
```

### Removing Outliers
Looking at the `summ_var` variable that we created, we can see that there is one provider in particular that prescribed a significantly higher amount than any other providers. Let's remove that observation from our data.
```{r removing outlier}
scribe_joint = subset(scribe_joint, summ_var<4000)
```


### Creating Factor Variables

Thinking back to the overview of the data, 
```{r}
scribe_joint = scribe_joint %>%
  mutate(Gender = as.factor(Gender),
         State  = as.factor(State),
         Credentials = as.factor(Credentials),
         Specialty   = as.factor(Specialty))
```

### Adjustments for Population
```{r sript_and_death rates by state}
# Creating a variable for per capita rates
overdose_df$Deaths <- as.numeric(gsub(",","",overdose_df$Deaths))
overdose_df$Population <- as.numeric(
  gsub(",","",overdose_df$Population))
    # Removing commas first to avoid errors in math
overdose_df$deaths_per_capita = (
  overdose_df$Deaths/overdose_df$Population
  )*100000 # per 100 thousand

df = scribe_joint %>%
  group_by(State) %>%
  summarise(state_opioid_volume = sum(summ_var)) %>%
  arrange(State)
overdose_df$state_opioid_volume <- df$state_opioid_volume
    # To give us total opioid prescriptions in each state

# which will allow us to determine the rate-per-thousand people
overdose_df %<>% mutate(opioids_per_cap =
                          (state_opioid_volume/Population)*1000)
```

## Data Visualization
```{r gg1/2 -- script rates by specialty/cred w/ gender}
# Differences when grouped by specialty
ggp1 = ggplot(
  scribe_joint,aes(x = Specialty, y = summ_var, fill = Gender)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(x = "Specialty",
       y = "Individual Prescriptions Written",
       fill = "Gender",
       title = "Opioid Prescription Rates by Specialty & Gender") +
  theme(plot.title = element_text(hjust = 0.5, face="bold.italic"), 
        axis.title.x = element_text(size = 12),
        axis.text.x = element_text(size = 7, angle=50,margin = margin(t = 20)),
        axis.title.y = element_text(size = 12),
        legend.title = element_text(face="bold", size = 10))
# Differences when grouped by credentials
ggp2 = ggplot(
  scribe_joint,aes(x = Credentials, y = summ_var, fill = Gender)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(x = "Credential",
       y = "Individual Prescriptions Written",
       fill = "Gender",
       title = "Opioid Prescription Rates by Credentials & Gender") +
  theme(plot.title = element_text(hjust = 0.5, face="bold.italic"), 
        axis.title.x = element_text(size = 12),
        axis.text.x = element_text(size = 7),
        axis.title.y = element_text(size = 12),
        legend.title = element_text(face="bold", size = 10))
ggp1
ggp2
```

```{r ggp3/4 - # of providers by gender}
ggp3 = scribe_joint %>%
  group_by(Gender) %>%
  summarise(plyr::count(Specialty))%>%
  ggplot(.,aes(x = x, y = freq, fill = Gender)) +
  geom_bar(stat = "identity", position = "dodge")+
  labs(x = "Specialty",
       y = "Number of Providers",
       fill = "Gender",
       title = "Number of Providers by Specialty & Gender") +
  theme(plot.title = element_text(hjust = 0.5, face="bold.italic"), 
        axis.title.x = element_text(size = 12),
        axis.text.x = element_text(size = 7, angle=50,margin = margin(t = 20)),
        axis.title.y = element_text(size = 12),
        legend.title = element_text(face="bold", size = 10))

ggp4 = scribe_joint %>%
  group_by(Gender) %>%
  summarise(plyr::count(Credentials))%>%
  ggplot(.,aes(x = x, y = freq, fill = Gender)) +
  geom_bar(stat = "identity", position = "dodge")+
  labs(x = "Credential",
       y = "Number of Providers",
       fill = "Gender",
       title = "Number of Providers by Credentials & Gender") +
  theme(plot.title = element_text(hjust = 0.5, face="bold.italic"), 
        axis.title.x = element_text(size = 12),
        axis.text.x = element_text(size = 7),
        axis.title.y = element_text(size = 12),
        legend.title = element_text(face="bold", size = 10))

ggp3
ggp4

```

```{r plot map of US death rates}
library(usmap)
library(ggpattern)
statepop <- statepop %>% filter(abbr!='DC')
statepop$per_cap_death <- overdose_df$deaths_per_capita
  
map_of_deaths <- plot_usmap(data = statepop, values = "per_cap_death", color = "black")+
  labs(title = "Deaths From Opioid Overdose in US",
               subtitle = "Population per 100,000")+
  theme(plot.title = element_text(face="bold", size = 14),
        plot.subtitle = element_text(face = "italic"),
        legend.title = element_text(face = "bold", size = 8),
        legend.position = c(0.9, 0.15))+
  scale_fill_continuous(
    low = "white", high = "red", name = "Death Rate (2014)")
map_of_deaths
```

```{r plot overdose rates and script volume}
plot_overdose_script = ggplot(
  overdose_df, aes(x=opioids_per_cap, y=deaths_per_capita)) + 
  geom_point(size=4, alpha=.6, color="black")+
  geom_smooth(method = 'lm', se=F, color="red")+
  geom_smooth(method = "loess", se=F, color="blue")+
  xlim(0,102)+
  ylab("Overdose Death Rate (per 100,000)")+
  xlab("Opioid Prescriptions Written (per 1,000 people)")+
  labs(title = 
         "State Overdose Death Rate & Number of Opioid Prescrptiions")
plot_overdose_script
```

# Training & Testing
Now that the data has been cleaned and we have seen it graphically, we can begin to train a model to fit the data. There are several different ways that this data could be modeled, we will be focusing on a couple of models 
### Partioining of Data for Training and Testing
```{r set seed split dfs and rm(NPI)}
set.seed(1234) # Setting seed for reproducibility
train_df = scribe_joint %>%
  sample_frac(0.8) # Partitioning 20% to be used for testing 
test_df  = anti_join(
  scribe_joint, train_df, by = 'NPI')

# Now lets remove the `NPI` variable to make work easier henceforth
train_df = train_df %>% select(-c("NPI"))
test_df = test_df %>% select(-c("NPI"))

```

## *Model 1 fin*: Linear Regression

```{r copy df for m1}
# Let's make a copy of the train/test set that we can play with for this model
m1_train <- train_df
m1_test  <- test_df
```

If we want to answer this question, we should remove the variables of the individual opioids and only include the `summ_var` variable we created for total opioids prescribed. Removing the additional variables would prevent double-counting in the data.

```{r}
# Using variable from working_df from before to get list of variables to remove from m1_train
colnames(working_df)
m1_train = m1_train %>%
  select(-c("HYDROCODONE.ACETAMINOPHEN",
            "OXYCONTIN","ACETAMINOPHEN.CODEINE",
            "FENTANYL","Opioid.Prescriber",
            "TRAMADOL.HCL","HYDROMORPHONE.HCL",
            "METHADONE.HCL","MORPHINE.SULFATE",
            "MORPHINE.SULFATE.ER",
            "OXYCODONE.ACETAMINOPHEN",
            "OXYCODONE.HCL"))
```

```{r fwd/back/step selection w/ summaries}
p_load(tidyverse, caret, leaps)

set.seed(123)
# Forward step wise selection
fwd_step = train(
  summ_var ~.,
  data = m1_train,
  trControl = trainControl(method = "cv", number = 5),
  method = "leapForward",
  tuneGrid = expand.grid(nvmax = 1:15)
)
fwd_step$results
fwd_step$bestTune

# Backward step wise selection
back_step = train(
  summ_var ~.,
  data = m1_train,
  trControl = trainControl(method = "cv", number = 5),
  method = "leapBackward",
  tuneGrid = expand.grid(nvmax = 1:15)
)
back_step$results
back_step$r
```

```{r best coef selections}
fin_fwd_step_list = as.data.frame(coef(fwd_step$finalModel,12))
fin_bck_step_list = as.data.frame(coef(back_step$finalModel,13))
print(fin_bck_step_list)
print(fin_fwd_step_list)
```


Now that we have a list of variables, let's think about which to include in our model. The Orthopedic Surgery  specialty is considerably significant in both models, so let's create a dummy variable indicating if a provider is an orthopedic surgeon. `CARISOPRODOL`, 
`CYCLOBENZAPRINE.HCL`,`METHOCARBAMOL`, `ONDANSETRON.HCL`, `LYRICA`, `TIZANIDINE.HCL`, `LORAZEPAM`,`PREDNISONE`, and `GABAPENTIN`. These are all the different drugs that appeared in both best-selected models.

`DIVALPROEX.SODIUM.ER` was a negative indicator in both models, so we will also include it in our final model. 
```{r}
m1_train = m1_train %>%
  mutate(orth_surg_dummy = as.factor(
    if_else(Specialty == "Orthopedic Surgery",1,0))
  )

mod1 = lm(data = m1_train, method = "lm", summ_var~
           orth_surg_dummy + CARISOPRODOL +
           CYCLOBENZAPRINE.HCL+METHOCARBAMOL+
           ONDANSETRON.HCL+LYRICA+TIZANIDINE.HCL+
            LORAZEPAM+PREDNISONE+GABAPENTIN)
summary(mod1)
```

Looking at some measurements of model accuracy
```{r}
m1_train$resid <- resid(mod1)
m1_train$fitted <- fitted(mod1)

sqrt(mean((m1_train$summ_var - m1_train$fitted)^2)) # to calculate MSE
```
Not the best-performing model, but let's see nonetheless how it performs when facing the testing set. Perhaps the insight to learn is that we cannot successfully predict opioid prescription rates from these lists of other prescribed medications

## *Model 2*: Decision Trees
Are we able to predict the Specialty of a provider based on prescriptions rates and other variables?
```{r, cache=TRUE}
p_load(rpart, ranger, parsnip, tidverse)
m2_train <- train_df
set.seed(1234)
default_cv = m2_train %>% vfold_cv(v =5)
# Define the decision tree
default_tree = decision_tree(mode ="classification",
                             cost_complexity = tune(),
                             tree_depth = tune(),
                             min_n =10) %>%
  set_engine("rpart")
# Defining recipe
default_recipe = recipe(Gender ~., data = m2_train)
# Defining workflow
default_flow = workflow() %>%
  add_model(default_tree) %>%
  add_recipe(default_recipe)
# Tuning
default_cv_fit = default_flow %>%
  tune_grid(
    default_cv,
    grid = expand_grid(
      cost_complexity = seq(0, 0.15, by = 0.01),
      tree_depth = c(1,2,5,10),
    ),
    metrics = metric_set(accuracy, roc_auc)
  )
# Fitting the best model
best_flow = default_flow %>%
  finalize_workflow(select_best(default_cv_fit, metric = "accuracy")) %>%
  fit(data = m2_train)
# Choosing the best model
best_tree = best_flow %>% extract_fit_parsnip()
# Plotting the tree
rpart::best_tree$fit %>% rpart.plot()
```

## *Model 3*: k-NN
```{r}
set.seed(1234)
m3_full <- scribe_joint
m3_full = m3_full %>%
  select(-c("HYDROCODONE.ACETAMINOPHEN",
            "OXYCONTIN","ACETAMINOPHEN.CODEINE",
            "FENTANYL","Opioid.Prescriber",
            "TRAMADOL.HCL","HYDROMORPHONE.HCL",
            "METHADONE.HCL","MORPHINE.SULFATE",
            "MORPHINE.SULFATE.ER",
            "OXYCODONE.ACETAMINOPHEN",
            "OXYCODONE.HCL"))

m3_train = m3_full %>%
  sample_frac(0.8) 
m3_test  = anti_join(
  m3_full, m3_train, by = 'NPI')
m3_train %<>% select(-c("NPI"))
m3_test  %<>% select(-c("NPI"))

m3_train <- fastDummies::dummy_cols(m3_train)
m3_test <-  fastDummies::dummy_cols(m3_test)

m3_train_subset = m3_train %>% select(-c(1:4))
m3_train_subset %<>% select(-c("summ_var"))
# Removing any non-integer variables that are now accounted for with the 
# dummy variables 
m3_test_subset = m3_test %>% select(-c(1:4))

m3_test %<>% select(-c(1:4))
```

```{r eval=FALSE}
library(class)
knn.26 <- knn(train=m3_train_subset, test=m3_test, cl=m3_test_subset, k=2)
```


## *Model 4 fin*: Support Vector Machine (SVM)

For this model, let's see if we can accurately predict the gender of a provider.
```{r}
m4_train <- train_df
m4_test <- test_df

pacman::p_load(e1071)
```

Now to prepare the data for making our predictions of interest
```{r SVM clean and prep}
# Defining our variables of prediction and outcome
x = m4_train[,-1]
y = m4_train[1]
```


Now running the model (takes a while, be patient)
```{r svm model selection, cache=TRUE}
svm_model = svm(Gender ~ .,
                 data = m4_train)
summary(svm_model)

  
preds = predict(svm_model,x)
# Ensure caret package is loaded for line below
confusionMatrix(preds, y$Gender)
```



# Testing
## *Model 1:*
```{r}
m1_test = m1_train %>%
  mutate(m1_test = as.factor(
    if_else(Specialty == "Orthopedic Surgery",1,0))
  )
# Using the variables selected with stepwise algorithm
mod1t = lm(data = m1_test, summ_var~
           orth_surg_dummy + CARISOPRODOL +
           CYCLOBENZAPRINE.HCL+METHOCARBAMOL+
           ONDANSETRON.HCL+LYRICA+TIZANIDINE.HCL+
            LORAZEPAM+PREDNISONE+GABAPENTIN)
summary(mod1t)

m1_test$resid <- resid(mod1t)
m1_test$fitted <- fitted(mod1t)
sqrt(mean((m1_test$summ_var - m1_test$fitted)^2)) # to calculate MSE
```
Looking at the testing results, while the model may not be very accurate, it is at least consistently inaccurate when looking at the data. Looking at the plot below, we can see a wide range of values of predicted versus actual, but the linear line of approximation 

```{r actual/pred mod1}
plot(x=m1_test$fitted,
     m1_test$summ_var,
     xlab = "Predicted Values",
     ylab = "Observed Values",
     main = "Linear Model")
abline(a = 0,                                        
       b = 1,
       col = "red",
       lwd = 2)
```

## *Model 2:*
## *Model 3:*
## *Model 4 fin*
Using the same SVM approach as with the testing set.
```{r svm testing, cache=TRUE}
xt = m4_train[,-1]
yt = m4_train[1]

svm_model_test = svm(Gender ~ .,
                 data = m4_test)
summary(svm_model_test)

  
predst = predict(svm_model_test,xt)
# Ensure caret package is loaded for line below
confusionMatrix(predst, yt$Gender)
```
Again, the results are comparable. 
# Conclusions

Evn though some of our mdoels we're not great at predictnig, it was reassuring
to see that they are at least consistently inconsistent in their prediction.

make a table showing all results compared

```{r sandbox, eval=FALSE}
xts = m4_train[,-256]
yts = m4_train[256]

svm_model_test_s = svm(summ_var ~ .,
                 data = m4_test)
summary(svm_model_test_s)

  
predst_s = predict(svm_model_test_s,xts)
# Ensure caret package is loaded for line below
confusionMatrix(predst_s, yts$summ_var)
```

